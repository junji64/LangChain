{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3722f2",
   "metadata": {},
   "source": [
    "#### References\n",
    "\n",
    "* https://learn.deeplearning.ai/courses/langchain/lesson/1/introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e002dc4",
   "metadata": {},
   "source": [
    "# LangChain for LLM Application Development\n",
    "\n",
    "\n",
    "* Langchain은 **LLM(대형 언어 모델) 애플리케이션 개발**을 위한 오픈 소스 프레임워크입니다. GPT-4와 같은 **LLM을 외부 데이터와 결합**합니다. \n",
    "* Langchain은 Python 또는 JavaScript(TypeScript) 패키지로 제공됩니다. \n",
    "* Langchain은 **구성요소화(composition)** 와 **모듈성**에 중점을 둡니다. 여기에는 개별 구성요소를 서로 **결합하거나 단독으로 사용**할 수 있는 모듈식 구성요소가 있습니다. \n",
    "* Langchain은 **다양한 사례에 적용**될 수 있으며, 더 많은 엔드 투 엔드 애플리케이션을 위해 모듈식 구성 요소를 결합할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bdc9d8",
   "metadata": {},
   "source": [
    "### LangChain의 주요 구성 요소\n",
    "\n",
    "LangChain은 유연성과 모듈성을 강조합니다. 자연어 처리 파이프라인을 별도의 모듈식 구성 요소로 나누어 개발자가 필요에 따라 워크플로를 맞춤화할 수 있습니다. Langchain 프레임워크는 6개의 모듈로 나눌 수 있으며, 각 모듈은 LLM과의 상호 작용의 다양한 측면을 허용합니다.\n",
    "\n",
    "* **Models**\n",
    "  - LLMs: 20+ integrations\n",
    "  - Chat Models\n",
    "  - Text Embedding Models: 10+ integrations\n",
    " \n",
    "* **Prompts**\n",
    "  - Prompt templates\n",
    "  - Output Parsers: 5+ implementations\n",
    "    - Retry/fixing logic\n",
    "  - Example Selectors: 5+ implementations\n",
    " \n",
    "* **Indexes**\n",
    "  - Document loaders: 50+ implementations\n",
    "  - Text Splitters: 10+ implementations\n",
    "  - Vector stores: 10+ integrations\n",
    "  - Retriviers: 5+ integrations/implementations\n",
    " \n",
    "* **Chains**\n",
    "  - Prompt + LLM + Output parsing\n",
    "  - Can be used as building blocks for longer chains\n",
    "  - More application specific chains: 20+ types\n",
    " \n",
    "* **Agents**\n",
    "  - Agent Types: 5+ types\n",
    "    - Algorithms for getting LLMs to use tools\n",
    "  - Agent Toolkits: 10+ implementations\n",
    "    - Agents armed with specific tools for a specific application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a20132",
   "metadata": {},
   "source": [
    "## 01. Models, Prompts and Parsers\n",
    "\n",
    "여기에서는 모델, 프롬프트 및 파서(parser)를 다룰 것입니다. \n",
    "\n",
    "* **모델(model)** 은 많은 것을 뒷받침하는 언어 모델을 나타냅니다. \n",
    "* **프롬프트(prompt)** 는 모델에 전달할 입력을 만드는 스타일을 나타냅니다. \n",
    "* 그리고 **파서(parser)** 는 반대쪽에 위치하며, 모델의 출력을 가져오고 더 구조화된 형식으로 구문 분석하여 다운스트림 작업을 수행할 수 있습니다.\n",
    "\n",
    "LLM을 사용하여 애플리케이션을 구축할 때 재사용 가능한 모델이 있는 경우가 많습니다. 우리는 반복적으로 모델을 프롬프트하고 출력을 파싱하므로 LangChain은 이러한 유형의 작업을 수행하기 위한 손쉬운 추상화 세트를 제공합니다.\n",
    "\n",
    "### Outline\n",
    "\n",
    " * Direct API calls to OpenAI\n",
    " * API calls through LangChain:\n",
    "   * Prompts\n",
    "   * Models\n",
    "   * Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f38bd",
   "metadata": {},
   "source": [
    "## Get your [OpenAI API Key](https://platform.openai.com/account/api-keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506bbca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv\n",
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0990db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3bd26",
   "metadata": {},
   "source": [
    "## Chat API : OpenAI\n",
    "\n",
    "OpenAI에 대한 직접 API 호출부터 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3c0c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, # 이것는 모델 출력의 무작위성 정도를 말합니다.[0~1]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83849309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa4b005",
   "metadata": {},
   "source": [
    "이제 모델, 프롬프트 및 파서에 대한 LangChain 추상화에 동기를 부여하기 위해, 영어가 아닌 언어로 고객으로부터 이메일을 받았다고 가정해 보겠습니다.\n",
    "이것이 가능한 지 확인하기 위해 제가 사용할 다른 언어는 \"영국 해적 언어(English pirate language)\"입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2b1afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "341ee6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"\"\"American English in a calm and respectful tone\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5014a4d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks \n",
      "into a style that is American English in a calm and respectful tone.\n",
      "text: ```\n",
      "Arrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse,the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \n",
    "into a style that is {style}.\n",
    "text: ```{customer_email}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e9ff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f96221c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I could really use your help right now, friend.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57856a5e",
   "metadata": {},
   "source": [
    "## Chat API : LangChain\n",
    "\n",
    "**LangChain**을 사용하여 동일한 작업을 수행할 수 있는 방법을 시도해 봅시다.\n",
    "\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de31149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46e04fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a224255c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000022B15EE9B10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000022B160E9090>, temperature=0.0, openai_api_key='sk-proj-WboK1MNhFmaIRtv0EQOjT3BlbkFJSpST32fblerT9sJ7WEAr', openai_proxy='')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is langchain's abstraction for chatGPT API Endpoint\n",
    "# To control the randomness and creativity of the generated text by an LLM, use temperature = 0.0\n",
    "chat = ChatOpenAI(temperature=0.0, model=\"gpt-3.5-turbo\")\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7624ee6f",
   "metadata": {},
   "source": [
    "### Prompt template\n",
    "\n",
    "prompts 는 모델을 프로그래밍하는 새로운 방법입니다. prompts 는 모델에 전달할 입력을 생성하는 스타일을 나타냅니다. prompts는 종종 여러 구성 요소로 구성됩니다. prompt_template 과 Example selector 는 prompts를 쉽게 구성하고 사용할 수 있는 기본 클래스와 함수를 제공합니다.\n",
    "\n",
    "템플릿 문자열(template_string)을 정의하고 이 템플릿 문자열과 langChain의 ChatPromptTemplate을 사용하여 PromptTemplate 을 생성하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67780778",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Translate the text \\\n",
    "that is delimited by triple backticks \\\n",
    "into a style that is {style}. \\\n",
    "text: ```{text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a7c4a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54341345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['style', 'text'], template='Translate the text that is delimited by triple backticks into a style that is {style}. text: ```{text}```\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b0a8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['style', 'text']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248f4994",
   "metadata": {},
   "source": [
    "위의 Prompt_template에는 style과 text라는 2개의 필드가 있습니다. 이 Prompt_template 에서 원본 템플릿 문자열을 추출할 수도 있습니다. 이제 텍스트를 다른 스타일로 번역하려면 번역할 style과 text를 정의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40faf310",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_style = \"\"\"American English in a calm and respectful tone\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc7c1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse, \\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dbe7b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = prompt_template.format_messages(\n",
    "                    style=customer_style,\n",
    "                    text=customer_email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bc24bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f965a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Translate the text that is delimited by triple backticks into a style that is American English in a calm and respectful tone. text: ```\\nArrr, I be fuming that me blender lid flew off and splattered me kitchen walls with smoothie! And to make matters worse, the warranty don't cover the cost of cleaning up me kitchen. I need yer help right now, matey!\\n```\\n\"\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b7be587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Call the LLM to translate to the style of the customer message\n",
    "customer_response = chat(customer_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5deb3a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am really frustrated that my blender lid flew off and splattered my kitchen walls with smoothie! And to make matters worse, the warranty doesn't cover the cost of cleaning up my kitchen. I need your help right now, friend!\n"
     ]
    }
   ],
   "source": [
    "print(customer_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7d5352",
   "metadata": {},
   "source": [
    "이제 고객 서비스 담당자가 원래 언어로 고객에게 응답하기를 바랍니다. 그들은 공손한 메시지입니다. 우리는 서비스 메시지가 이 해적 스타일로 번역되도록 지정하겠습니다.\n",
    "그래서 우리는 그것이 영국 해적에서 말하는 공손한 어조로 되기를 원합니다.\n",
    "이전에 해당 프롬프트 템플릿을 만들었기 때문에 멋진 점은 이제 **해당 프롬프트 템플릿을 재사용**하고 원하는 **출력 스타일이 이 service style pirate** 이고 **텍스트가 이 서비스 응답**임을 지정할 수 있다는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d0b0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_reply = \"\"\"Hey there customer, \\\n",
    "the warranty does not cover \\\n",
    "cleaning expenses for your kitchen \\\n",
    "because it's your fault that \\\n",
    "you misused your blender \\\n",
    "by forgetting to put the lid on before \\\n",
    "starting the blender. \\\n",
    "Tough luck! See ya!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36d25e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_style_pirate = \"\"\"a polite tone that speaks in English Pirate\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa444f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the text that is delimited by triple backticks into a style that is a polite tone that speaks in English Pirate. text: ```Hey there customer, the warranty does not cover cleaning expenses for your kitchen because it's your fault that you misused your blender by forgetting to put the lid on before starting the blender. Tough luck! See ya!\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17eff574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahoy there, valued customer! Regrettably, the warranty be not coverin' the cost o' cleanin' yer galley due to yer own negligence in misusin' yer blender. Ye forgot to secure the lid afore startin' the blender, savvy? 'Tis a tough break, matey! Fare thee well!\n"
     ]
    }
   ],
   "source": [
    "service_response = chat(service_messages)\n",
    "print(service_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e41b0f",
   "metadata": {},
   "source": [
    "정교한 애플리케이션을 구축할 때 프롬프트가 상당히 길고 상세할 수 있으며, 프롬프트 템플릿은 가능한 한 좋은 프롬프트를 재사용하는 데 도움이 되는 유용한 추상화입니다.\n",
    "\n",
    "<img src=\"why_prompt_template.PNG\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50f712",
   "metadata": {},
   "source": [
    "LangChain 프롬프트 라이브러리의 또 다른 측면은 파싱(parsing)도 지원한다는 것입니다. LLM을 사용하여 복잡한 애플리케이션을 구축할 때 특정 키워드 사용과 같은 특정 형식으로 출력을 생성하도록 LLM에 지시하는 경우가 많습니다. 아래의 예는 LLM을 사용하여 React 라는 프레임워크를 사용하여 **일련의 사고 추론(chain of thought reasoning)** 이라는 것을 수행하는 것을 보여줍니다. LLM은 **Thought, Action, Observation**과 같은 키워드를 사용하여 **ReAct라는 프레임워크**를 사용하여 일련의 사고 추론을 수행합니다. \n",
    "* **Thought**은 LLM이 생각하는 것이며, LLM에 생각할 수 있는 공간을 제공함으로써 LLM은 보다 정확한 결론을 얻을 수 있습니다. \n",
    "* **Action**은 특정 작업을 수행하기 위한 키워드이고, \n",
    "* **Observation**은 LLM이 특정 작업을 통해 무엇을 학습했는지 보여주는 키워드입니다.  \n",
    "\n",
    "**Thought, Action, Observation**과 같은 특정 키워드를 사용하도록 LLM에 지시하는 프롬프트가 있는 경우 **이러한 키워드를 파서와 결합하여 해당 키워드로 태그가 지정된 텍스트를 추출**할 수 있습니다.\n",
    "\n",
    "<img src=\"prompt_output.PNG\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ce5055",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "LLM 출력이 다음과 같이 Dicrionary 또는 JSON 으로 표시되는 방법을 정의하는 것으로 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec5af038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': False, 'delivery_days': 5, 'price_value': 'pretty affordable!'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c1a9d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "This leaf blower is pretty amazing.  It has four settings:\\\n",
    "candle blower, gentle breeze, windy city, and tornado. \\\n",
    "It arrived in two days, just in time for my wife's \\\n",
    "anniversary present. \\\n",
    "I think my wife liked it so much she was speechless. \\\n",
    "So far I've been the only one using it, and I've been \\\n",
    "using it every other morning to clear the leaves on our lawn. \\\n",
    "It's slightly more expensive than the other leaf blowers \\\n",
    "out there, but I think it's worth it for the extra features.\n",
    "\"\"\"\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product \\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "gift\n",
    "delivery_days\n",
    "price_value\n",
    "\n",
    "text: {text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cfbbf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='For the following text, extract the following information:\\n\\ngift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\\n\\ndelivery_days: How many days did it take for the product to arrive? If this information is not found, output -1.\\n\\nprice_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\\n\\nFormat the output as JSON with the following keys:\\ngift\\ndelivery_days\\nprice_value\\n\\ntext: {text}\\n'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ffa78860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"gift\": true,\n",
      "    \"delivery_days\": 2,\n",
      "    \"price_value\": [\"It's slightly more expensive than the other leaf blowers out there\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "chat = ChatOpenAI(temperature=0.0)\n",
    "response = chat(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3da15cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a5badbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# You will get an error by running this line of code \u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# because'gift' is not a dictionary\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 'gift' is a string\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m response\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgift\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# You will get an error by running this line of code \n",
    "# because'gift' is not a dictionary\n",
    "# 'gift' is a string\n",
    "response.content.get('gift')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97280c1e",
   "metadata": {},
   "source": [
    "### Parse the LLM output string into a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7952a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b61f146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gift_schema = ResponseSchema(name=\"gift\",\n",
    "                             description=\"Was the item purchased\\\n",
    "                             as a gift for someone else? \\\n",
    "                             Answer True if yes,\\\n",
    "                             False if not or unknown.\")\n",
    "delivery_days_schema = ResponseSchema(name=\"delivery_days\",\n",
    "                                      description=\"How many days\\\n",
    "                                      did it take for the product\\\n",
    "                                      to arrive? If this \\\n",
    "                                      information is not found,\\\n",
    "                                      output -1.\")\n",
    "price_value_schema = ResponseSchema(name=\"price_value\",\n",
    "                                    description=\"Extract any\\\n",
    "                                    sentences about the value or \\\n",
    "                                    price, and output them as a \\\n",
    "                                    comma separated Python list.\")\n",
    "\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7995fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5452543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b8656f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f41a589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_template_2 = \"\"\"\\\n",
    "For the following text, extract the following information:\n",
    "\n",
    "gift: Was the item purchased as a gift for someone else? \\\n",
    "Answer True if yes, False if not or unknown.\n",
    "\n",
    "delivery_days: How many days did it take for the product\\\n",
    "to arrive? If this information is not found, output -1.\n",
    "\n",
    "price_value: Extract any sentences about the value or price,\\\n",
    "and output them as a comma separated Python list.\n",
    "\n",
    "text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=review_template_2)\n",
    "\n",
    "messages = prompt.format_messages(text=customer_review, \n",
    "                                format_instructions=format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd180e7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following text, extract the following information:\n",
      "\n",
      "gift: Was the item purchased as a gift for someone else? Answer True if yes, False if not or unknown.\n",
      "\n",
      "delivery_days: How many days did it take for the productto arrive? If this information is not found, output -1.\n",
      "\n",
      "price_value: Extract any sentences about the value or price,and output them as a comma separated Python list.\n",
      "\n",
      "text: This leaf blower is pretty amazing.  It has four settings:candle blower, gentle breeze, windy city, and tornado. It arrived in two days, just in time for my wife's anniversary present. I think my wife liked it so much she was speechless. So far I've been the only one using it, and I've been using it every other morning to clear the leaves on our lawn. It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"gift\": string  // Was the item purchased                             as a gift for someone else?                              Answer True if yes,                             False if not or unknown.\n",
      "\t\"delivery_days\": string  // How many days                                      did it take for the product                                      to arrive? If this                                       information is not found,                                      output -1.\n",
      "\t\"price_value\": string  // Extract any                                    sentences about the value or                                     price, and output them as a                                     comma separated Python list.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "768fd32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31542dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"gift\": true,\n",
      "\t\"delivery_days\": 2,\n",
      "\t\"price_value\": [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05ae3790",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dict = output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ea3fb48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gift': True,\n",
       " 'delivery_days': 2,\n",
       " 'price_value': [\"It's slightly more expensive than the other leaf blowers out there, but I think it's worth it for the extra features.\"]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3b7547b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b349bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get('delivery_days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fdb14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
